{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HW 6\n",
    "\n",
    "Muyuan Zhang\n",
    "\n",
    "u1430770\n",
    "\n",
    "07/23/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Acquisition + Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('fonts/ARIAL.csv')\n",
    "df.drop(columns=['font', 'fontVariant', 'strength', 'italic', 'orientation',\n",
    "'m_top', 'm_left', 'originalH', 'originalW', 'h', 'w'], inplace=True)\n",
    "\n",
    "# takes in one of these types of dataframe and returns 2 numpy arrays:\n",
    "# Xs which is a #samples x 20 x 20 array containing the pixel values, and\n",
    "# Ys which is a #samples x 1 array containing the ascii value for each character\n",
    "def parse_df(df):\n",
    "    Xs = df.drop(columns='m_label').to_numpy(dtype=np.float64)\n",
    "    Xs = np.array([x.reshape(20, 20) for x in Xs], dtype=np.float64)/255\n",
    "    Xs = np.reshape(Xs, (-1, 1, 20, 20))\n",
    "\n",
    "    # assign each character a smaller index value\n",
    "    index, Ys = np.unique(df[\"m_label\"].to_numpy(), return_inverse=True)\n",
    "    \n",
    "    return Xs, Ys, index\n",
    "\n",
    "Xs, Ys, index = parse_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build a PyTorch Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "\n",
    "        self.convolution1 = nn.Conv2d(1, 8, 3)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.dense1 = nn.Linear(576, 4000)\n",
    "\n",
    "        self.convolution2 = nn.Conv2d(8, 64, 3)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.dense2 = nn.Linear(4000, 3209)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.convolution1(x)))\n",
    "        x = self.pool2(F.relu(self.convolution2(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "\n",
    "        return num_features\n",
    "\n",
    "network = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(model, epochs, data, labels):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam( model.parameters(), lr=1e-4)\n",
    "\n",
    "    model.float()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Exploration and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Evaluate the network using cross validation (splitting data into training/testing). What is its accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def evaluate(model, data, labels):\n",
    "    #load some test data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(data.float())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network: %d%%' % (100 * correct / total))\n",
    "\n",
    "data = torch.from_numpy(Xs)\n",
    "labels = torch.from_numpy(Ys)\n",
    "data, labels = data.to(), labels.to()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, train_size=0.5, shuffle=True)\n",
    "\n",
    "train(network, 10, X_train, y_train)\n",
    "evaluate(network, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Create and train a different network topology (add more convolution layers, experiment with normalization (batch normalization or dropout), explore other types/sizes of layer). Try to find a topology that works better than the one described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network2, self).__init__()\n",
    "\n",
    "        self.convolution1 = nn.Conv2d(1, 8, 2)\n",
    "        self.pooling1 = nn.MaxPool2d(2, 2)\n",
    "        self.dense1 = nn.Linear(128, 5000)\n",
    "\n",
    "        self.convolution2 = nn.Conv2d(8, 64, 2)\n",
    "        self.pooling2 = nn.MaxPool2d(2, 2)\n",
    "        self.dense2 = nn.Linear(5000, 3098)\n",
    "\n",
    "        self.convolution3 = nn.Conv2d(64, 128, 2)\n",
    "        self.pooling3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pooling1(F.relu(self.convolution1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pooling2(F.relu(self.convolution2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pooling3(F.relu(self.convolution3(x)))\n",
    "\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dense2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "\n",
    "        return num_features\n",
    "\n",
    "network2 = Network2()\n",
    "data = torch.from_numpy(Xs)\n",
    "labels = torch.from_numpy(Ys)\n",
    "data, labels = data.to(), labels.to()\n",
    "\n",
    "train(network2, 10, data, labels)\n",
    "evaluate(network2, data, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Test the accuracy of your network with character inputs from a DIFFERENT font set. How does it perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "courier_df = pd.read_csv('fonts/COURIER.csv')\n",
    "courier_df.drop(columns=['font', 'fontVariant', 'strength', 'italic', 'orientation', 'm_top', 'm_left', 'originalH', 'originalW', 'h', 'w'], inplace=True)\n",
    "courier_x, courier_y, keys = parse_df(courier_df)\n",
    "courier_inputs, courier_labels = torch.from_numpy(courier_x).to(), torch.from_numpy(courier_y).to()\n",
    "\n",
    "evaluate(network2, courier_inputs, courier_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Train your best network on inputs from the data from at least 2 different fonts. How does your accuracy compare to the 1-font case? What accuracy do you see when testing with inputs from a font you didn't train on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambria_df = pd.read_csv('fonts/CAMBRIA.csv')\n",
    "bernard_df = pd.read_csv('fonts/BERNARD.csv')\n",
    "\n",
    "cambria_df.drop(columns=['font', 'fontVariant', 'strength', 'italic', 'orientation', 'm_top', 'm_left', 'originalH', 'originalW', 'h', 'w'], inplace=True)\n",
    "bernard_df.drop(columns=['font', 'fontVariant', 'strength', 'italic', 'orientation', 'm_top', 'm_left', 'originalH', 'originalW', 'h', 'w'], inplace=True)\n",
    "\n",
    "cambria_x, cambria_y, keys = parse_df(cambria_df)\n",
    "bernard_x, bernard_y, keys = parse_df(bernard_df)\n",
    "\n",
    "cambria_inputs, cambria_labels = torch.from_numpy(cambria_x).to(), torch.from_numpy(cambria_y).to()\n",
    "bernard_inputs, bernard_labels = torch.from_numpy(bernard_x).to(), torch.from_numpy(bernard_y).to()\n",
    "\n",
    "evaluate(network2, cambria_inputs, cambria_labels)\n",
    "evaluate(network2, bernard_inputs, bernard_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNoise(x):\n",
    "    return max(min(x + np.random.normal() / 5, 1), 0)\n",
    "\n",
    "X_noisy = []\n",
    "\n",
    "for value in Xs:\n",
    "    font_value = value[0]\n",
    "    noisy_font_value = np.vectorize(addNoise)(font_value)\n",
    "    X_noisy.append(noisy_font_value)\n",
    "\n",
    "for i in range(500, 510):\n",
    "    image = Image.fromarray(np.uint8(X_noisy[i] * 255), 'L')\n",
    "    display(image)\n",
    "\n",
    "X_noisy = torch.from_numpy(np.reshape(np.array(X_noisy), (-1, 1, 20, 20)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnDenoiseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CnnDenoiseNet, self).__init__()\n",
    "\n",
    "        self.encodedSize = 32\n",
    "\n",
    "        self.c1Output = 8\n",
    "        self.c2Output = 8\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, self.c1Output, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(self.c1Output, self.c2Output, 3, padding=1)\n",
    "\n",
    "        self.downscalingSize = 20 // 4\n",
    "        self.flatteningSize = self.downscalingSize * self.downscalingSize * self.c2Output\n",
    "\n",
    "        self.fc1 = nn.Linear(self.flatteningSize, 64)\n",
    "        self.fc2 = nn.Linear(64, self.encodedSize)\n",
    "\n",
    "        self.fc3 = nn.Linear(self.encodedSize, 64)\n",
    "        self.fc4 = nn.Linear(64, self.flatteningSize)\n",
    "\n",
    "\n",
    "        self.upSample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        self.cv3 = nn.Conv2d(self.c2Output, self.c1Output, 3, padding=1)\n",
    "        self.cv4 = nn.Conv2d(self.c1Output, 1, 3, padding=1)\n",
    "\n",
    "        self.double()\n",
    "\n",
    "\n",
    "    def compress(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.pool(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.pool(x))\n",
    "        x = x.view(-1, self.flatteningSize)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def decompress(self, x):\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = x.view(-1, self.c2Output, self.downscalingSize, self.downscalingSize)\n",
    "        x = self.upSample(x)\n",
    "        x = F.relu(self.cv3(x))\n",
    "        x = self.cv4(self.upSample(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.compress(x)\n",
    "        x = self.decompress(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "denoise_network = CnnDenoiseNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotComparisons(model):\n",
    "\n",
    "    plt.figure( figsize=(20, 20) )\n",
    "\n",
    "    testing_loader = torch.utils.data.DataLoader( X_noisy, batch_size=8, shuffle=True, num_workers=0 )\n",
    "\n",
    "    for i, image in enumerate(testing_loader):\n",
    "        if i >= 8:\n",
    "            break\n",
    "        images = image[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            denoised = model(images.to(torch.float32).to(device))\n",
    "            for j in range( len(images) ):\n",
    "\n",
    "                # Original\n",
    "                ax = plt.subplot(16, 8, i*16 + j + 1)\n",
    "                plt.imshow(images[j].cpu().reshape(20,20), cmap=\"Greys\", interpolation=None)\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "\n",
    "                # Denoised\n",
    "                ax = plt.subplot(16, 8, i*16 + j + 1 + 8)\n",
    "                plt.imshow(denoised[j].cpu().reshape(20,20), cmap=\"Greys\", interpolation=None)\n",
    "                ax.get_xaxis().set_visible(False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plotComparisons(denoise_network)\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
